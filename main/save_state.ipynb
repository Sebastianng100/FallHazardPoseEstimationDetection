{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b555168b",
   "metadata": {},
   "source": [
    "efficientnet_fall_classification_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb242e1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "IMAGES_ROOT = PROJECT_ROOT / \"fall_dataset\" / \"images\"\n",
    "MODEL_PATH = PROJECT_ROOT / \"saved_model\" / \"efficientnet_baseline_fall_model.pth\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def label_from_name(path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Return 1 for FALL, 0 for NOT-FALL based on filename.\n",
    "    Handles names like 'fall123.jpg' vs 'not fallen001.jpg'.\n",
    "    \"\"\"\n",
    "    name = path.stem.lower()\n",
    "    norm = re.sub(r\"[\\W_]+\", \" \", name).strip()\n",
    "\n",
    "    not_fall_patterns = [\n",
    "        \"not fall\", \"notfall\", \"not fallen\", \"notfallen\", \"no fall\", \"nofall\",\n",
    "        \"standing\", \"walk\", \"walking\", \"sit\", \"sitting\", \"upright\"\n",
    "    ]\n",
    "    if any(p in norm for p in not_fall_patterns):\n",
    "        return 0\n",
    "\n",
    "    if \"fall\" in norm or norm.startswith(\"fallen\"):\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "class NameLabelDataset(Dataset):\n",
    "    def __init__(self, directory: Path, transform=None):\n",
    "        self.directory = Path(directory)\n",
    "        self.transform = transform\n",
    "        self.paths = self._gather_images(self.directory)\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in: {self.directory}\")\n",
    "\n",
    "        ys = [label_from_name(p) for p in self.paths]\n",
    "        self.class_counts = {0: ys.count(0), 1: ys.count(1)}\n",
    "\n",
    "    @staticmethod\n",
    "    def _gather_images(d: Path) -> List[Path]:\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "        paths = [p for p in d.iterdir() if p.suffix.lower() in exts]\n",
    "        for sub in [x for x in d.iterdir() if x.is_dir()]:\n",
    "            paths.extend([p for p in sub.rglob(\"*\") if p.suffix.lower() in exts])\n",
    "        return sorted(paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y = label_from_name(p)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "def build_model(model_name=\"efficientnet_b0\", num_classes: int = 2, freeze_backbone: bool = True):\n",
    "    if model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif model_name == \"efficientnet_b3\":\n",
    "        model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "def epoch_loop(model, loader, device, optimizer=None, criterion=None) -> Tuple[float, float, float, float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    If optimizer is None => evaluation mode.\n",
    "    Returns: (loss, acc, precision, recall, f1, confusion_matrix)\n",
    "    \"\"\"\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels) if criterion else torch.tensor(0.0, device=device)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(total, 1)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "    return avg_loss, acc, prec, rec, f1, cm\n",
    "\n",
    "def main(args):\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    train_dir = IMAGES_ROOT / \"train\"\n",
    "    val_dir = IMAGES_ROOT / \"val\"\n",
    "\n",
    "    tfms = get_transforms()\n",
    "    train_ds = NameLabelDataset(train_dir, transform=tfms)\n",
    "    val_ds = NameLabelDataset(val_dir, transform=tfms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    total_train = len(train_ds)\n",
    "    w0 = total_train / (2.0 * max(train_ds.class_counts.get(0, 1), 1))\n",
    "    w1 = total_train / (2.0 * max(train_ds.class_counts.get(1, 1), 1))\n",
    "    class_weights = torch.tensor([w0, w1], dtype=torch.float32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(args.model, num_classes=2, freeze_backbone=not args.unfreeze_backbone).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "\n",
    "    print(f\"Project root: {PROJECT_ROOT}\")\n",
    "    print(f\"Train dir:    {train_dir} (count={len(train_ds)} | class_counts={train_ds.class_counts})\")\n",
    "    print(f\"Val dir:      {val_dir}   (count={len(val_ds)} | class_counts={val_ds.class_counts})\")\n",
    "    print(f\"Saving model to: {MODEL_PATH}\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loss, tr_acc, tr_p, tr_r, tr_f1, tr_cm = epoch_loop(model, train_loader, device, optimizer, criterion)\n",
    "        va_loss, va_acc, va_p, va_r, va_f1, va_cm = epoch_loop(model, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{args.epochs} \"\n",
    "              f\"| Train L {tr_loss:.4f} A {tr_acc:.3f} P {tr_p:.3f} R {tr_r:.3f} F1 {tr_f1:.3f} \"\n",
    "              f\"| Val L {va_loss:.4f} A {va_acc:.3f} P {va_p:.3f} R {va_r:.3f} F1 {va_f1:.3f}\")\n",
    "        print(f\"  Train CM:\\n{tr_cm}\")\n",
    "        print(f\"  Val   CM:\\n{va_cm}\\n\")\n",
    "\n",
    "        if va_f1 > best_val_f1:\n",
    "            best_val_f1 = va_f1\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Saved best model\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--unfreeze-backbone\", action=\"store_true\",\n",
    "                        help=\"Fine-tune the whole EfficientNet instead of just the classifier.\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"efficientnet_b0\",\n",
    "                        choices=[\"efficientnet_b0\", \"efficientnet_b3\"],\n",
    "                        help=\"Which EfficientNet variant to use\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106900e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fall_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ed9f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "IMAGES_ROOT = PROJECT_ROOT / \"fall_dataset\" / \"images\"\n",
    "MODEL_PATH = PROJECT_ROOT / \"saved_model\" / \"efficientnet_fall_model.pth\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def label_from_name(path: Path) -> int:\n",
    "    name = path.stem.lower()\n",
    "    norm = re.sub(r\"[\\W_]+\", \" \", name).strip()\n",
    "    not_fall_patterns = [\n",
    "        \"not fall\", \"notfall\", \"not fallen\", \"notfallen\", \"no fall\", \"nofall\",\n",
    "        \"standing\", \"walk\", \"walking\", \"sit\", \"sitting\", \"upright\"\n",
    "    ]\n",
    "    if any(p in norm for p in not_fall_patterns):\n",
    "        return 0\n",
    "    if \"fall\" in norm or norm.startswith(\"fallen\"):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "class NameLabelDataset(Dataset):\n",
    "    def __init__(self, directory: Path, transform=None):\n",
    "        self.directory = Path(directory)\n",
    "        self.transform = transform\n",
    "        self.paths = self._gather_images(self.directory)\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in: {self.directory}\")\n",
    "        ys = [label_from_name(p) for p in self.paths]\n",
    "        self.class_counts = {0: ys.count(0), 1: ys.count(1)}\n",
    "\n",
    "    @staticmethod\n",
    "    def _gather_images(d: Path) -> List[Path]:\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "        paths = [p for p in d.iterdir() if p.suffix.lower() in exts]\n",
    "        for sub in [x for x in d.iterdir() if x.is_dir()]:\n",
    "            paths.extend([p for p in sub.rglob(\"*\") if p.suffix.lower() in exts])\n",
    "        return sorted(paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y = label_from_name(p)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "def build_model(model_name=\"efficientnet_b0\", num_classes: int = 2, freeze_backbone: bool = True):\n",
    "    if model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    elif model_name == \"efficientnet_b3\":\n",
    "        model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "    return model\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        n_class = pred.size(1)\n",
    "        log_preds = torch.log_softmax(pred, dim=1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (n_class - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), 1 - self.smoothing)\n",
    "        return torch.mean(torch.sum(-true_dist * log_preds, dim=1))\n",
    "\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def epoch_loop(model, loader, device, optimizer=None, criterion=None, mixup=False) -> Tuple[float, float, float, float, float, np.ndarray]:\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss, total = 0.0, 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device, dtype=torch.long)\n",
    "\n",
    "        if is_train and mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "            logits = model(imgs)\n",
    "            loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "        else:\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels) if criterion else torch.tensor(0.0, device=device)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(total, 1)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "    return avg_loss, acc, prec, rec, f1, cm\n",
    "\n",
    "def main(args):\n",
    "    set_seed(args.seed)\n",
    "    train_dir, val_dir = IMAGES_ROOT / \"train\", IMAGES_ROOT / \"val\"\n",
    "    tfms = get_transforms()\n",
    "    train_ds, val_ds = NameLabelDataset(train_dir, tfms), NameLabelDataset(val_dir, tfms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    total_train = len(train_ds)\n",
    "    w0 = total_train / (2.0 * max(train_ds.class_counts.get(0, 1), 1))\n",
    "    w1 = total_train / (2.0 * max(train_ds.class_counts.get(1, 1), 1))\n",
    "    class_weights = torch.tensor([w0, w1], dtype=torch.float32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(args.model, num_classes=2, freeze_backbone=not args.unfreeze_backbone).to(device)\n",
    "    \n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)  # Novel strategy 1\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)  # Novel strategy 2\n",
    "    \n",
    "    swa_model = AveragedModel(model)\n",
    "    swa_start = int(0.75 * args.epochs)\n",
    "    swa_scheduler = SWALR(optimizer, swa_lr=1e-4)\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loss, tr_acc, tr_p, tr_r, tr_f1, tr_cm = epoch_loop(model, train_loader, device, optimizer, criterion, mixup=True)  # Novel strategy 3\n",
    "        va_loss, va_acc, va_p, va_r, va_f1, va_cm = epoch_loop(model, val_loader, device, criterion=criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{args.epochs} \"\n",
    "              f\"| Train L {tr_loss:.4f} A {tr_acc:.3f} P {tr_p:.3f} R {tr_r:.3f} F1 {tr_f1:.3f} \"\n",
    "              f\"| Val L {va_loss:.4f} A {va_acc:.3f} P {va_p:.3f} R {va_r:.3f} F1 {va_f1:.3f}\")\n",
    "        print(f\"  Train CM:\\n{tr_cm}\")\n",
    "        print(f\"  Val   CM:\\n{va_cm}\\n\")\n",
    "\n",
    "        if va_f1 > best_val_f1:\n",
    "            best_val_f1 = va_f1\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Saved best model\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--unfreeze-backbone\", action=\"store_true\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"efficientnet_b0\", choices=[\"efficientnet_b0\", \"efficientnet_b3\"])\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ac5d3",
   "metadata": {},
   "source": [
    "resnet_fall_classification_baseline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34eaa9",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "IMAGES_ROOT = PROJECT_ROOT / \"fall_dataset\" / \"images\"\n",
    "MODEL_PATH = PROJECT_ROOT / \"saved_model\" / \"resnet_baseline_fall_model.pth\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def label_from_name(path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Return 1 for FALL, 0 for NOT-FALL based on filename.\n",
    "    Handles names like 'fall123.jpg' vs 'not fallen001.jpg'.\n",
    "    \"\"\"\n",
    "    name = path.stem.lower()\n",
    "    norm = re.sub(r\"[\\W_]+\", \" \", name).strip()\n",
    "\n",
    "    not_fall_patterns = [\n",
    "        \"not fall\", \"notfall\", \"not fallen\", \"notfallen\", \"no fall\", \"nofall\",\n",
    "        \"standing\", \"walk\", \"walking\", \"sit\", \"sitting\", \"upright\"\n",
    "    ]\n",
    "    if any(p in norm for p in not_fall_patterns):\n",
    "        return 0\n",
    "\n",
    "    if \"fall\" in norm or norm.startswith(\"fallen\"):\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "class NameLabelDataset(Dataset):\n",
    "    def __init__(self, directory: Path, transform=None):\n",
    "        self.directory = Path(directory)\n",
    "        self.transform = transform\n",
    "        self.paths = self._gather_images(self.directory)\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in: {self.directory}\")\n",
    "\n",
    "        ys = [label_from_name(p) for p in self.paths]\n",
    "        self.class_counts = {0: ys.count(0), 1: ys.count(1)}\n",
    "\n",
    "    @staticmethod\n",
    "    def _gather_images(d: Path) -> List[Path]:\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "        paths = [p for p in d.iterdir() if p.suffix.lower() in exts]\n",
    "        for sub in [x for x in d.iterdir() if x.is_dir()]:\n",
    "            paths.extend([p for p in sub.rglob(\"*\") if p.suffix.lower() in exts])\n",
    "        return sorted(paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y = label_from_name(p)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "def build_model(num_classes: int = 2, freeze_backbone: bool = True):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "\n",
    "def epoch_loop(model, loader, device, optimizer=None, criterion=None) -> Tuple[float, float, float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    If optimizer is None => evaluation mode.\n",
    "    Returns: (loss, acc, precision, recall, f1, confusion_matrix)\n",
    "    \"\"\"\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels) if criterion else torch.tensor(0.0, device=device)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(total, 1)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "    return avg_loss, acc, prec, rec, f1, cm\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    train_dir = IMAGES_ROOT / \"train\"\n",
    "    val_dir = IMAGES_ROOT / \"val\"\n",
    "\n",
    "    tfms = get_transforms()\n",
    "    train_ds = NameLabelDataset(train_dir, transform=tfms)\n",
    "    val_ds = NameLabelDataset(val_dir, transform=tfms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    total_train = len(train_ds)\n",
    "    w0 = total_train / (2.0 * max(train_ds.class_counts.get(0, 1), 1))\n",
    "    w1 = total_train / (2.0 * max(train_ds.class_counts.get(1, 1), 1))\n",
    "    class_weights = torch.tensor([w0, w1], dtype=torch.float32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(num_classes=2, freeze_backbone=not args.unfreeze_backbone).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "\n",
    "    print(f\"Project root: {PROJECT_ROOT}\")\n",
    "    print(f\"Train dir:    {train_dir} (count={len(train_ds)} | class_counts={train_ds.class_counts})\")\n",
    "    print(f\"Val dir:      {val_dir}   (count={len(val_ds)} | class_counts={val_ds.class_counts})\")\n",
    "    print(f\"Saving model to: {MODEL_PATH}\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loss, tr_acc, tr_p, tr_r, tr_f1, tr_cm = epoch_loop(model, train_loader, device, optimizer, criterion)\n",
    "        va_loss, va_acc, va_p, va_r, va_f1, va_cm = epoch_loop(model, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{args.epochs} \"\n",
    "              f\"| Train L {tr_loss:.4f} A {tr_acc:.3f} P {tr_p:.3f} R {tr_r:.3f} F1 {tr_f1:.3f} \"\n",
    "              f\"| Val L {va_loss:.4f} A {va_acc:.3f} P {va_p:.3f} R {va_r:.3f} F1 {va_f1:.3f}\")\n",
    "        print(f\"  Train CM (rows true [0,1], cols pred [0,1]):\\n{tr_cm}\")\n",
    "        print(f\"  Val   CM (rows true [0,1], cols pred [0,1]):\\n{va_cm}\\n\")\n",
    "\n",
    "        if va_f1 > best_val_f1:\n",
    "            best_val_f1 = va_f1\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Saved best model (val F1={best_val_f1:.3f}) → {MODEL_PATH}\\n\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--unfreeze-backbone\", action=\"store_true\",\n",
    "                        help=\"Fine-tune the whole ResNet18 instead of just the final layer.\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcaeed",
   "metadata": {},
   "source": [
    "resnet_fall_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24894ce7",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "IMAGES_ROOT = PROJECT_ROOT / \"fall_dataset\" / \"images\"\n",
    "MODEL_PATH = PROJECT_ROOT / \"saved_model\" / \"resnet_fall_model.pth\"\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def label_from_name(path: Path) -> int:\n",
    "    name = path.stem.lower()\n",
    "    norm = re.sub(r\"[\\W_]+\", \" \", name).strip()\n",
    "\n",
    "    not_fall_patterns = [\n",
    "        \"not fall\", \"notfall\", \"not fallen\", \"notfallen\", \"no fall\", \"nofall\",\n",
    "        \"standing\", \"walk\", \"walking\", \"sit\", \"sitting\", \"upright\"\n",
    "    ]\n",
    "    if any(p in norm for p in not_fall_patterns):\n",
    "        return 0\n",
    "\n",
    "    if \"fall\" in norm or norm.startswith(\"fallen\"):\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "class NameLabelDataset(Dataset):\n",
    "    def __init__(self, directory: Path, transform=None):\n",
    "        self.directory = Path(directory)\n",
    "        self.transform = transform\n",
    "        self.paths = self._gather_images(self.directory)\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in: {self.directory}\")\n",
    "\n",
    "        ys = [label_from_name(p) for p in self.paths]\n",
    "        self.class_counts = {0: ys.count(0), 1: ys.count(1)}\n",
    "\n",
    "    @staticmethod\n",
    "    def _gather_images(d: Path) -> List[Path]:\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "        paths = [p for p in d.iterdir() if p.suffix.lower() in exts]\n",
    "        for sub in [x for x in d.iterdir() if x.is_dir()]:\n",
    "            paths.extend([p for p in sub.rglob(\"*\") if p.suffix.lower() in exts])\n",
    "        return sorted(paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y = label_from_name(p)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "def build_model(num_classes: int = 2, freeze_backbone: bool = True):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "\n",
    "def epoch_loop(model, loader, device, optimizer=None, criterion=None, scheduler=None) -> Tuple[float, float, float, float, np.ndarray]:\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels) if criterion else torch.tensor(0.0, device=device)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / max(total, 1)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "    return avg_loss, acc, prec, rec, f1, cm\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    train_dir = IMAGES_ROOT / \"train\"\n",
    "    val_dir = IMAGES_ROOT / \"val\"\n",
    "\n",
    "    tfms = get_transforms()\n",
    "    train_ds = NameLabelDataset(train_dir, transform=tfms)\n",
    "    val_ds = NameLabelDataset(val_dir, transform=tfms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(num_classes=2, freeze_backbone=not args.unfreeze_backbone).to(device)\n",
    "\n",
    "    criterion = FocalLoss(alpha=1, gamma=2)\n",
    "\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=args.lr, steps_per_epoch=len(train_loader), epochs=args.epochs\n",
    "    )\n",
    "\n",
    "    print(f\"Project root: {PROJECT_ROOT}\")\n",
    "    print(f\"Train dir:    {train_dir} (count={len(train_ds)} | class_counts={train_ds.class_counts})\")\n",
    "    print(f\"Val dir:      {val_dir}   (count={len(val_ds)} | class_counts={val_ds.class_counts})\")\n",
    "    print(f\"Saving model to: {MODEL_PATH}\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loss, tr_acc, tr_p, tr_r, tr_f1, tr_cm = epoch_loop(model, train_loader, device, optimizer, criterion, scheduler)\n",
    "        va_loss, va_acc, va_p, va_r, va_f1, va_cm = epoch_loop(model, val_loader, device, None, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{args.epochs} \"\n",
    "              f\"| Train L {tr_loss:.4f} A {tr_acc:.3f} P {tr_p:.3f} R {tr_r:.3f} F1 {tr_f1:.3f} \"\n",
    "              f\"| Val L {va_loss:.4f} A {va_acc:.3f} P {va_p:.3f} R {va_r:.3f} F1 {va_f1:.3f}\")\n",
    "        print(f\"  Train CM (rows true [0,1], cols pred [0,1]):\\n{tr_cm}\")\n",
    "        print(f\"  Val   CM (rows true [0,1], cols pred [0,1]):\\n{va_cm}\\n\")\n",
    "\n",
    "        if va_f1 > best_val_f1:\n",
    "            best_val_f1 = va_f1\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Saved best model (val F1={best_val_f1:.3f}) → {MODEL_PATH}\\n\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--unfreeze-backbone\", action=\"store_true\",\n",
    "                        help=\"Fine-tune the whole ResNet18 instead of just the final layer.\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60017ebd",
   "metadata": {},
   "source": [
    "main.py\n",
    "\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(__file__))\n",
    "RESNET_MODEL_PATH = os.path.join(BASE_DIR, \"saved_model\", \"resnet_fall_model.pth\")\n",
    "EFFICIENTNET_MODEL_PATH = os.path.join(BASE_DIR, \"saved_model\", \"efficientnet_fall_model.pth\")\n",
    "HAZARD_MODEL_PATH = os.path.join(BASE_DIR, \"saved_model\", \"hazard_yolov83\", \"weights\", \"best.pt\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fall_classes = [\"Not Fall\", \"Fall\"]\n",
    "\n",
    "# ---------- Load ResNet ----------\n",
    "resnet_model = models.resnet18(weights=None)\n",
    "resnet_model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(resnet_model.fc.in_features, len(fall_classes))\n",
    ")\n",
    "resnet_model.load_state_dict(torch.load(RESNET_MODEL_PATH, map_location=device))\n",
    "resnet_model.to(device)\n",
    "resnet_model.eval()\n",
    "\n",
    "efficientnet_model = models.efficientnet_b0(weights=None)\n",
    "efficientnet_model.classifier[1] = nn.Linear(efficientnet_model.classifier[1].in_features, len(fall_classes))\n",
    "efficientnet_model.load_state_dict(torch.load(EFFICIENTNET_MODEL_PATH, map_location=device))\n",
    "efficientnet_model.to(device)\n",
    "efficientnet_model.eval()\n",
    "\n",
    "hazard_model = YOLO(HAZARD_MODEL_PATH)\n",
    "\n",
    "fall_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_resnet(image):\n",
    "    img = Image.fromarray(image)\n",
    "    img_t = fall_transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = resnet_model(img_t)\n",
    "        probs = torch.softmax(outputs, dim=1)[0]\n",
    "\n",
    "    conf, pred = torch.max(probs, 0)\n",
    "    label = fall_classes[pred.item()]\n",
    "\n",
    "    probs_dict = {fall_classes[i]: f\"{probs[i].item()*100:.1f}%\" for i in range(len(fall_classes))}\n",
    "\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-9)).item()\n",
    "\n",
    "    return (\n",
    "        f\"[ResNet]\\n\"\n",
    "        f\"Prediction: {label}\\n\"\n",
    "        f\"Confidence: {conf.item()*100:.1f}%\\n\"\n",
    "        f\"Probabilities: {probs_dict}\\n\"\n",
    "        f\"Uncertainty (entropy): {entropy:.3f}\"\n",
    "    )\n",
    "\n",
    "def predict_efficientnet(image):\n",
    "    img = Image.fromarray(image)\n",
    "    img_t = fall_transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = efficientnet_model(img_t)\n",
    "        probs = torch.softmax(outputs, dim=1)[0]\n",
    "\n",
    "    conf, pred = torch.max(probs, 0)\n",
    "    label = fall_classes[pred.item()]\n",
    "\n",
    "    probs_dict = {fall_classes[i]: f\"{probs[i].item()*100:.1f}%\" for i in range(len(fall_classes))}\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-9)).item()\n",
    "\n",
    "    return (\n",
    "        f\"[EfficientNet]\\n\"\n",
    "        f\"Prediction: {label}\\n\"\n",
    "        f\"Confidence: {conf.item()*100:.1f}%\\n\"\n",
    "        f\"Probabilities: {probs_dict}\\n\"\n",
    "        f\"Uncertainty (entropy): {entropy:.3f}\"\n",
    "    )\n",
    "\n",
    "def predict_hazard(image):\n",
    "    results = hazard_model.predict(image, conf=0.25)\n",
    "    return results[0].plot()\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"Fall & Hazard Detection\")\n",
    "\n",
    "    mode = gr.Dropdown(\n",
    "        choices=[\"ResNet Fall Detection\", \"EfficientNet Fall Detection\", \"Hazard Detection\"], \n",
    "        label=\"Select Mode\", value=\"ResNet Fall Detection\"\n",
    "    )\n",
    "\n",
    "    img = gr.Image(type=\"numpy\", label=\"Upload Image\")\n",
    "    run = gr.Button(\"Run Inference\", variant=\"primary\")\n",
    "\n",
    "    out_txt = gr.Textbox(label=\"Prediction\", lines=2)\n",
    "    out_img = gr.Image(type=\"numpy\", label=\"Hazard Detection Output\")\n",
    "\n",
    "    def inference(image, mode):\n",
    "        if mode == \"ResNet Fall Detection\":\n",
    "            return predict_resnet(image), None\n",
    "        elif mode == \"EfficientNet Fall Detection\":\n",
    "            return predict_efficientnet(image), None\n",
    "        else:\n",
    "            return None, predict_hazard(image)\n",
    "\n",
    "    run.click(inference, inputs=[img, mode], outputs=[out_txt, out_img])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f89c3",
   "metadata": {},
   "source": [
    "requirements.txt\n",
    "\n",
    "gradio\n",
    "gradio_client\n",
    "torch==2.3.1\n",
    "torchvision==0.18.1\n",
    "mediapipe==0.10.14\n",
    "ultralytics==8.3.26\n",
    "opencv-python==4.10.0.84\n",
    "numpy==1.26.4\n",
    "cvzone\n",
    "tensorflow\n",
    "scikit-learn\n",
    "label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484c63e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
